{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b035bd-f29c-4393-ae71-58986ef29bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai-whisper torch sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394abd45-0e09-46cc-aab4-a6b921709229",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756fbae5-e95f-4b2b-8400-8668b2a70fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb41eff-d9fb-40ed-bdd5-64c43d40d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-generativeai tensorflow-addons tensorflow python-dotenv pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "484d2308-2fcf-4b79-b569-3748d8439a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting ffmpeg\n",
      "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: ffmpeg\n",
      "  Building wheel for ffmpeg (setup.py): started\n",
      "  Building wheel for ffmpeg (setup.py): finished with status 'done'\n",
      "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6138 sha256=eeee111b3b423d2221fc9af8de08fa364616c5bb017b06a4e74b6a26ebd950f8\n",
      "  Stored in directory: c:\\users\\ant pc\\appdata\\local\\pip\\cache\\wheels\\26\\21\\0c\\c26e09dff860a9071683e279445262346e008a9a1d2142c4ad\n",
      "Successfully built ffmpeg\n",
      "Installing collected packages: ffmpeg\n",
      "Successfully installed ffmpeg-1.4\n"
     ]
    }
   ],
   "source": [
    "pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38dafeb9-a817-460f-8bdf-21e5f5837674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Flask in c:\\anaconda3\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (0.8.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\anaconda3\\lib\\site-packages (from Flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\anaconda3\\lib\\site-packages (from Flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\anaconda3\\lib\\site-packages (from Flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\anaconda3\\lib\\site-packages (from Flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\anaconda3\\lib\\site-packages (from Flask) (1.6.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.24.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.158.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (2.37.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in c:\\anaconda3\\lib\\site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda3\\lib\\site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\anaconda3\\lib\\site-packages (from google-generativeai) (4.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from click>=8.1.3->Flask) (0.4.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda3\\lib\\site-packages (from Jinja2>=3.1.2->Flask) (2.1.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.69.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.69.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Flask python-dotenv google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2390da82-80a9-4310-a7ad-d4e66a3a7857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6217ad75-c8b9-4644-99cc-8aeb85af34a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797ac165-b929-4fa6-a550-e3da9649ba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\python.exe\n",
      "C:\\Program Files\\Python310\\python.exe\n",
      "C:\\Users\\ANT pc\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85433759-8d94-495f-b955-5e597935d1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document part-1 uploaded successfully.\n",
      "Transcription response received for part: 1\n",
      "Document part-2 uploaded successfully.\n",
      "Transcription response received for part: 2\n",
      "Document part-3 uploaded successfully.\n",
      "Transcription response received for part: 3\n",
      "Transcription Result:\n",
      " **Chapter 1: Whispers of the Past Bookstore**\n",
      "\n",
      "*   The bookstore, \"Whispers of the Past,\" is located in a bustling city.\n",
      "*   The bookstore's atmosphere is characterized by the scent of aged paper and ink, and a feeling of timelessness.\n",
      "*   The bookstore's exterior evokes a sense of history and inviting exploration.\n",
      "*   Mr. Thompson, the bookstore owner, is a long-standing figure in the neighborhood.\n",
      "*   Mr. Thompson meticulously arranges the books and enjoys interacting with customers.\n",
      "\n",
      "\n",
      "**Chapter 2: Clara's Arrival**\n",
      "\n",
      "*   Clara, a young woman seeking inspiration for her writing, moves to the city.\n",
      "*   Clara enters \"Whispers of the Past\" on a rainy afternoon.\n",
      "*   Clara immediately feels a strong connection to the bookstore's atmosphere.\n",
      "*   Clara's journey begins as she explores the shop's extensive collection.\n",
      "*   She is particularly drawn to a book titled \"The Forgotten Tales.\"\n",
      "\n",
      "\n",
      "**Chapter 3: Encounter with \"The Forgotten Tales\"**\n",
      "\n",
      "*   Clara picks up and opens \"The Forgotten Tales,\" a dusty volume.\n",
      "*   The book's stories cover themes of love, loss, courage, and despair.\n",
      "*   The narratives are engaging and captivating for Clara.\n",
      "*   Clara becomes engrossed in the stories, losing track of time.\n",
      "*   Mr. Thompson observes Clara's interaction with the book.\n",
      "\n",
      "\n",
      "Chapter 4:  Finding Inspiration\n",
      "\n",
      "*   Clara, an aspiring writer, seeks writing advice from Mr. Thompson, a bookstore owner.\n",
      "*   Mr. Thompson encourages Clara to find her own voice and suggests exploring the poetry section for inspiration.\n",
      "*   Clara immerses herself in poetry, experiencing an emotional connection and a desire to create.\n",
      "*   Clara becomes a regular at the bookstore, fostering a relationship with Mr. Thompson.\n",
      "*   They engage in discussions about literature and life, sharing personal experiences.\n",
      "\n",
      "\n",
      "Chapter 5:  A Moment of Pause\n",
      "\n",
      "*   The bookstore closes for inventory, leading to Clara's disappointment and a change in plans.\n",
      "*   Clara seeks inspiration in the park, amid winter's beauty, rather than at the bookstore.\n",
      "*   She encounters an elderly woman feeding birds, sparking a meaningful conversation.\n",
      "*   The conversation prompts a shift in Clara's thinking about life's moments and dreams.\n",
      "*   Clara gains inspiration for her writing through the encounter and leaves feeling renewed.\n",
      "\n",
      "\n",
      "Chapter 6:  A New Beginning\n",
      "\n",
      "*   Clara returns to her writing, driven by the inspiration she gained.\n",
      "*   She works tirelessly, filling pages with her thoughts.\n",
      "*   She dedicates time to her writing until dawn.\n",
      "*   Clara returns to the bookstore the following day, carrying new determination.\n",
      "*   Mr. Thompson notices a change in Clara's demeanor, suggesting a change in her perspective.\n",
      "\n",
      "\n",
      "Chapter 7: Clara's Inspiration\n",
      "\n",
      "* Clara discovered a passion for storytelling.\n",
      "* She found encouragement from Mr. Thompson.\n",
      "* Books became a source of friendship and inspiration.\n",
      "* Clara began crafting stories based on her experiences.\n",
      "* Her stories resonated with readers beyond her immediate surroundings.\n",
      "* The themes of connection, courage, and beauty were central to her work.\n",
      "\n",
      "\n",
      "Chapter 8: \"Whispers of the Past\" Grows\n",
      "\n",
      "* The bookstore, \"Whispers of the Past,\" became a hub for creativity.\n",
      "* It transitioned from a simple store to a supportive space for writers.\n",
      "* Workshops were held for aspiring authors.\n",
      "* Mr. Thompson maintained his dedication to curating the bookstore.\n",
      "* The bookstore fostered a sense of community among its visitors.\n",
      "* The shared experiences of the authors and Mr. Thompson created a special bond.\n",
      "\n",
      "\n",
      "Chapter 9:  A Lasting Impact\n",
      "\n",
      "* The bookstore became a sanctuary for both writers and dreamers.\n",
      "*  Countless stories emerged from the space.\n",
      "* The stories had the potential to inspire future generations.\n",
      "* The bookstore's success highlighted the power of stories.\n",
      "* Two souls found purpose and connection within the walls of the bookstore.\n",
      "* The partnership between Clara and Mr. Thompson became a defining characteristic of the bookstore.\n",
      "\n",
      "Segmented chapters from document file saved to: C:\\Users\\ANT pc\\Downloads\\AskJunior.ai Assessment Project\\Document-Chapter-Segmentation\\results\\document file\\document_segmented_chapters.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import re\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "# Configure the Gemini API\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Function to split the document into smaller parts\n",
    "def split_document(document_file_path, max_length):\n",
    "    with open(document_file_path, 'r', encoding='utf-8') as file:  # Specify encoding\n",
    "        content = file.read()\n",
    "\n",
    "    # Split the content into parts based on max_length\n",
    "    parts = []\n",
    "    while len(content) > max_length:\n",
    "        # Find the last space within the max_length limit\n",
    "        split_index = content.rfind(' ', 0, max_length)\n",
    "        if split_index == -1:  # No space found, split at max_length\n",
    "            split_index = max_length\n",
    "        parts.append(content[:split_index])\n",
    "        content = content[split_index:].strip()  # Remove leading spaces for the next part\n",
    "\n",
    "    if content:  # Add the remaining part\n",
    "        parts.append(content)\n",
    "\n",
    "    return parts\n",
    "\n",
    "# Function to transcribe document with segmented chapters\n",
    "def transcribe_document_with_segmented_chapters(document_file_path):\n",
    "    # Change the model to Gemini 1.5 Flash-8B\n",
    "    model = genai.GenerativeModel('models/gemini-1.5-flash-8b')  # Updated to use the Flash model\n",
    "    prompt = \"\"\"Please transcribe this document file and segment the transcription into meaningful chapters. \n",
    "    For each chapter, provide 5-6 detailed bullet points that summarize the key ideas, themes, or events discussed in that chapter. \n",
    "    Do not include any introductory phrases, personal comments, or conversational language. \n",
    "    Provide only the segmented chapters followed by the bullet points in the output.\"\"\"\n",
    "\n",
    "    # Split the document into parts if it exceeds the model's capacity\n",
    "    max_length = 2000  # Example: maximum number of characters per part\n",
    "    document_parts = split_document(document_file_path, max_length)\n",
    "\n",
    "    all_transcriptions = []\n",
    "    chapter_counter = 1  # Initialize chapter counter\n",
    "\n",
    "    # Process each part\n",
    "    for part in document_parts:\n",
    "        # Create a temporary file for the part\n",
    "        temp_file_path = \"temp_document_part.txt\"\n",
    "        with open(temp_file_path, 'w', encoding='utf-8') as temp_file:  # Specify encoding\n",
    "            temp_file.write(part)\n",
    "\n",
    "        # Upload the document part\n",
    "        document_file = genai.upload_file(path=temp_file_path, display_name=os.path.basename(temp_file_path))\n",
    "        print(f\"Document part-{len(all_transcriptions) + 1} uploaded successfully.\")  # Output part index\n",
    "\n",
    "        # Wait for a moment to ensure the file is in an active state\n",
    "        time.sleep(30)  # Increase the wait time if necessary\n",
    "\n",
    "        # Retry logic for generating transcription\n",
    "        for attempt in range(3):  # Try up to 3 times\n",
    "            try:\n",
    "                # Generate transcription\n",
    "                response = model.generate_content([\n",
    "                    prompt,\n",
    "                    document_file\n",
    "                ])\n",
    "                print(\"Transcription response received for part:\", len(all_transcriptions) + 1)  # Output part index\n",
    "\n",
    "                # Update chapter numbering in the response text\n",
    "                response_text = response.text\n",
    "\n",
    "                # Find all chapters in the response and update their numbering\n",
    "                chapters = re.findall(r'Chapter \\d+', response_text)\n",
    "                for chapter in chapters:\n",
    "                    current_chapter_number = int(chapter.split()[-1])\n",
    "                    new_chapter_number = chapter_counter + current_chapter_number - 1\n",
    "                    response_text = response_text.replace(chapter, f\"Chapter {new_chapter_number}\")\n",
    "\n",
    "                chapter_counter += len(chapters)  # Increment chapter counter by the number of chapters found\n",
    "\n",
    "                all_transcriptions.append(response_text)\n",
    "                break  # Exit the retry loop if successful\n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {attempt + 1}: Error during transcription for part {len(all_transcriptions) + 1}: {e}\")\n",
    "                time.sleep(5)  # Wait before retrying\n",
    "\n",
    "    return \"\\n\\n\".join(all_transcriptions)  # Combine all transcriptions # Define the document file path\n",
    "document_file_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'data', 'samples', 'document.txt'))\n",
    "\n",
    "# Example usage\n",
    "transcription_result = transcribe_document_with_segmented_chapters(document_file_path)\n",
    "if transcription_result:\n",
    "    print(\"Transcription Result:\\n\", transcription_result)\n",
    "else:\n",
    "    print(\"Failed to transcribe document.\")\n",
    "\n",
    "# Define the results folder path\n",
    "results_folder = os.path.abspath(os.path.join(os.getcwd(), '..', 'results', 'document file'))\n",
    "\n",
    "# Create the results directory if it doesn't exist\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "# Define the output file path for the segmented chapters of the document file\n",
    "output_md_file_path = os.path.join(results_folder, 'document_segmented_chapters.md')\n",
    "\n",
    "# Save the segmented chapters to the specified markdown file\n",
    "if transcription_result:\n",
    "    with open(output_md_file_path, 'w', encoding='utf-8') as f:  # Specify encoding\n",
    "        f.write(transcription_result)\n",
    "    print(f\"Segmented chapters from document file saved to: {output_md_file_path}\")\n",
    "else:\n",
    "    print(\"No transcription result to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4702d232-0110-4325-8c9d-3818b033e6bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video segment segment_000.mp4 uploaded successfully.\n",
      "Transcription response received for segment: segment_000.mp4\n",
      "Video segment segment_001.mp4 uploaded successfully.\n",
      "Transcription response received for segment: segment_001.mp4\n",
      "Video segment segment_002.mp4 uploaded successfully.\n",
      "Transcription response received for segment: segment_002.mp4\n",
      "Video segment segment_003.mp4 uploaded successfully.\n",
      "Transcription response received for segment: segment_003.mp4\n",
      "Transcription Result:\n",
      " Chapter 1\n",
      "\n",
      "* Desmond Doss was a conscientious objector in World War II.\n",
      "* He was a medic who refused to carry a weapon.\n",
      "* His religious beliefs were central to his decision.\n",
      "* Seventh-day Adventism was the guiding force behind his convictions.\n",
      "* Non-violence and a healthy, vegetarian diet were also key aspects of his beliefs.\n",
      "* His actions showcased his strong moral compass.\n",
      "\n",
      "\n",
      "Chapter 2\n",
      "\n",
      "* Doss's refusal to carry a weapon led to conflict and opposition from his fellow soldiers.\n",
      "* His superiors tried to pressure him into carrying a weapon.\n",
      "* Despite this, Doss insisted on maintaining his principled position.\n",
      "* Doss saved the lives of many soldiers without firing a single shot.\n",
      "* Doss's actions were eventually recognized and commended.\n",
      "\n",
      "Chapter 3\n",
      "\n",
      "* Doss's exceptional actions in battle, characterized by his saving of many lives without firing a shot, earn him recognition and respect.\n",
      "* His conscientious objection to participating in combat with a weapon stood in opposition to common practice.\n",
      "* Doss's commitment to his faith and beliefs became a distinguishing feature of his service.\n",
      "* Doss's refusal to carry a weapon was a source of conflict and pressure.\n",
      "* His unwavering commitment to saving lives earned him the respect of his fellow soldiers.\n",
      "\n",
      "\n",
      "Chapter 4\n",
      "\n",
      "* Following initial conflict with superiors, Doss is ultimately allowed to serve as a combat medic.\n",
      "* He receives training, placing him in the front lines to provide first-aid.\n",
      "* His compassion and determination to aid the injured proved crucial in battle.\n",
      "* His actions were commended by both superiors and subordinates.\n",
      "\n",
      "\n",
      "Chapter 5\n",
      "\n",
      "* Doss's profound dedication to service, despite opposition and unusual circumstances, led to a turning point in his relationship with his company.\n",
      "* A 25-mile march with full equipment and a rifle, and other significant events, served as a trial of his resolve.\n",
      "* His relentless determination to care for his comrades earned him the respect of the entire unit.\n",
      "* Doss served as a qualified combat medic and provided first-aid to wounded soldiers.\n",
      "* His dedication and compassion became exemplary for the entire unit.\n",
      "\n",
      "\n",
      "Chapter 6\n",
      "\n",
      "* Doss's role expanded to include front-line trauma care.\n",
      "* He excelled in his new role, proving his worth in combat.\n",
      "* His willingness to put the needs of others before his own exemplifies the core values of the Seventh-day Adventist denomination.\n",
      "* The 77th division gained experience and recognition for its combat medic and a conscientious objector.\n",
      "* Eventually, Doss's actions in battle are recognized by his unit and by other commanding officers.\n",
      "\n",
      "Chapter 13\n",
      "\n",
      "* The 77th Infantry Division was involved in the Battle of Guam.\n",
      "* The division suffered a significant number of casualties.\n",
      "* The conflict lasted for less than 20 days.\n",
      "* The total number of casualties for the division before the end of the war was 9,212.\n",
      "* The division faced a determined enemy.\n",
      "* The battle was fought to recapture U.S. territory from a Japanese garrison.\n",
      "\n",
      "\n",
      "Chapter 14\n",
      "\n",
      "* The battle was a bloody struggle, lasting from July 21st to August 10th, 1944.\n",
      "* The battle aimed to reclaim U.S. territory on the island of Guam.\n",
      "* Initial stages involved amphibious landings and naval bombardment.\n",
      "* A sizable Japanese garrison of nearly 20,000 troops defended the island.\n",
      "* Fighting took place in dense jungle terrain, putting significant pressure on American troops.\n",
      "* The U.S. objective was to regain control of Guam from a determined Japanese garrison.\n",
      "\n",
      "\n",
      "Chapter 15\n",
      "\n",
      "* Medical personnel faced significant danger and often had to avoid wearing insignia to avoid being targeted by enemy fire.\n",
      "* American medics were frequently treated as vulnerable targets, and therefore needed to be extremely careful.\n",
      "* The Japanese snipers and machine gunners prioritized the elimination of medical personnel.\n",
      "* The disregard for the Geneva Convention principles regarding medical personnel was a critical factor in the fighting.\n",
      "* Combat medics were often in harm's way, facing intense fire.\n",
      "* The battle was highly dangerous for medical personnel.\n",
      "\n",
      "\n",
      "Chapter 10\n",
      "\n",
      "* During the Battle of Guam, Corporal Desmond T. Doss was under intense fire, while attending to the casualties.\n",
      "* Doss went to great lengths to help and save numerous lives, including those of wounded soldiers.\n",
      "* Doss was involved in rescuing fellow servicemen.\n",
      "* Doss faced significant danger in his duties.\n",
      "* Doss's commitment to saving lives during the Battle of Guam is noteworthy.\n",
      "* The video highlights the bravery and dedication of Doss as a medic.\n",
      "\n",
      "\n",
      "Chapter 11\n",
      "\n",
      "* The Battle of Leyte, in the Philippines, was an intense and prolonged battle.\n",
      "* The battle, from October 17th to December 26th, 1944, featured significant naval and aerial bombardment.\n",
      "* The battle involved amphibious landings followed by inland fighting.\n",
      "* An immense U.S. coastal bombardment and amphibious landings led to heavy fighting.\n",
      "* The Battle of Leyte included a significant Japanese counterattack.\n",
      "* A fellow medic, Clarence Glenn, was wounded and needed assistance.\n",
      "\n",
      "\n",
      "Chapter 12\n",
      "\n",
      "* Doss and a fellow medic, Clarence Glenn, faced a serious Japanese counterattack.\n",
      "* During the counterattack, Glenn was severely wounded and needed immediate medical attention.\n",
      "* Doss, along with another soldier, went into harm's way to save their comrade.\n",
      "* They faced intense enemy fire while helping the wounded medic.\n",
      "* Glenn was saved and taken back to the aid station.\n",
      "* Doss's courage and his actions to save his fellow serviceman are key highlights.\n",
      "\n",
      "\n",
      "Chapter 13\n",
      "\n",
      "* Doss faced constant hunger, despite the rations provided.\n",
      "* The rations' tastelessness did not help with the hunger.\n",
      "* Doss was able to find coconuts.\n",
      "* Doss had to climb trees to find more coconuts, in order to combat his hunger.\n",
      "* Coconuts are mentioned as a source of nourishment.\n",
      "* Doss faced poorly aimed enemy fire and survived.\n",
      "\n",
      "\n",
      "Chapter 14\n",
      "\n",
      "* The Battle of Okinawa (1945) saw the 77th Infantry Division facing an extremely difficult assignment.\n",
      "* The Americans' task was to assault a 400-foot high cliff.\n",
      "* The cliff, known as the Maeda Escarpment, was nicknamed Hacksaw Ridge.\n",
      "* The Americans undertook an assault of the cliff.\n",
      "* The 77th Division's assigned objective was to secure the island as a base.\n",
      "* The battle lasted 81 days and was one of the bloodiest in the Pacific theater.\n",
      "\n",
      "\n",
      "Chapter 15\n",
      "\n",
      "* On April 29th, 1945, the 77th Division was tasked with climbing the escarpment.\n",
      "* The battle was extremely intense, and the division faced Japanese artillery, small arms, and machine gun fire.\n",
      "* The fighting was fierce, with many casualties sustained on both sides.\n",
      "* Doss's role as a combat medic included praying for his comrades prior to combat.\n",
      "* The Americans met with fierce Japanese resistance, and the struggle was brutal.\n",
      "* The video emphasizes the intense fighting and the many losses suffered.\n",
      "\n",
      "Chapter 16\n",
      "\n",
      "* American forces launched repeated assaults on a heavily fortified Japanese position.\n",
      "* The Japanese defenders were well-entrenched and employed camouflage effectively.\n",
      "* Initial assaults suffered significant casualties.\n",
      "* The video illustrates the brutal nature of the fighting.\n",
      "* The attacks were costly in terms of human life.\n",
      "* The determination and strategy of the Japanese defenders are implied.\n",
      "\n",
      "\n",
      "Chapter 17\n",
      "\n",
      "* On May 4th, Private First Class Desmond Doss found himself in the midst of fierce combat as his unit attacked a fortified Japanese position at the mouth of a cave.\n",
      "* Doss volunteered to assist four wounded comrades.\n",
      "* The lieutenant leading the attack on the emplacement intended to throw a grenade but was hit by enemy fire.\n",
      "* Doss's bravery and selflessness in the face of intense enemy fire are highlighted.\n",
      "* Doss's actions demonstrate remarkable courage under extremely dangerous conditions.\n",
      "\n",
      "\n",
      "Chapter 18\n",
      "\n",
      "* Doss successfully evacuated the wounded soldiers, one by one, back to his own lines.\n",
      "* The Japanese continued to attack during the night, throwing grenades and using mortars.\n",
      "* The Americans sought shelter in rock crevices.\n",
      "* The video illustrates the resilience and determination of the American troops.\n",
      "* Doss's unwavering focus on helping others is portrayed.\n",
      "\n",
      "Chapter 19\n",
      "\n",
      "* On May 5th, Doss came to the rescue of a wounded artillery officer.\n",
      "* The officer had gone to inspect the artillery guns.\n",
      "* Doss's left leg was injured in a previous action.\n",
      "* Doss faced even greater danger as he scaled a cargo net to reach the officer.\n",
      "* The officer was in a shell hole and bleeding heavily.\n",
      "\n",
      "Chapter 20\n",
      "\n",
      "* Doss provided first aid to the wounded officer despite heavy enemy fire and shelling.\n",
      "* The difficulty of maintaining composure under such stressful conditions is implied.\n",
      "* Doss's actions demonstrate his commitment to saving lives, even at great personal risk.\n",
      "* The video showcases the extreme danger faced by American soldiers.\n",
      "* Doss's focus on treating the wounded was highlighted.\n",
      "\n",
      "Chapter 21\n",
      "\n",
      "* The video depicts the fierce Japanese counterattack and overwhelming fire.\n",
      "* American soldiers were forced to retreat to the edge of the cliff.\n",
      "* The American troops were exhausted, but Doss remained determined to help others.\n",
      "* Doss spent hours carrying wounded soldiers to safety.\n",
      "* The arduous task of evacuating the wounded in the face of constant fire is highlighted.\n",
      "\n",
      "Chapter 22\n",
      "\n",
      "* Doss tied a rope to a tree, lowered the wounded soldiers to safety, and helped them to safety.\n",
      "* Doss's ingenious use of a rope to evacuate wounded men is a demonstration of his resourcefulness.\n",
      "* The dangers and complexities of a battlefield environment were shown.\n",
      "* The video depicts Doss's perseverance.\n",
      "* Despite his injuries and exhaustion, Doss's actions demonstrate determination to help.\n",
      "\n",
      "Chapter 23\n",
      "\n",
      "* Despite the dangers of potential enemy fire, Doss continued to prioritize the wounded.\n",
      "* Doss expressed prayer for guidance from the Lord as the soldiers were being lowered.\n",
      "* The video illustrates the importance of faith and determination in extreme circumstances.\n",
      "* Doss was eventually wounded himself.\n",
      "* The unrelenting nature of the battle is shown.\n",
      "\n",
      "Chapter 24\n",
      "\n",
      "* Doss was hit by a Japanese sniper's bullet and suffered a compound fracture to his arm.\n",
      "* The two men took cover in a shell hole to assess the severity of his wounds.\n",
      "* Doss provided instruction on how to bind his rifle stock to his arm to use as a splint.\n",
      "* This demonstrates his expertise in battlefield medicine.\n",
      "* The physical and psychological strain on the soldiers is implied.\n",
      "\n",
      "Chapter 160\n",
      "\n",
      "* Doss's bravery and sacrifice were recognized by the US Army.\n",
      "* Doss was awarded the Congressional Medal of Honor.\n",
      "* His heroism and selfless actions during the battle are emphasized.\n",
      "* The video depicts the magnitude of his courage.\n",
      "* Doss later led a small family farm with his wife.\n",
      "\n",
      "\n",
      "\n",
      "Chapter 276\n",
      "\n",
      "* A couple stands in front of a house, suggesting a settled life.\n",
      "* The setting appears to be post-war America, judging by the time period.\n",
      "* The couple represents the ideal of the American Dream, common during the era.\n",
      "* The image evokes a sense of peace, comfort, and normalcy.\n",
      "* The overall impression is one of a family and their home, a symbol of the American ideal.\n",
      "\n",
      "\n",
      "Chapter 27\n",
      "\n",
      "* The image displays medical items such as a medical kit and syringe, suggesting the prevalence of illness or injury.\n",
      "* Items also include a Bible, which indicates the role of religion in daily life, especially amid challenges.\n",
      "* The mix of objects hints at a time of hardships and the need for both medical care and spiritual guidance.\n",
      "* The imagery represents the challenges faced during the period, a combination of societal expectations and personal trials.\n",
      "* These objects could be part of a medical missionary or humanitarian aid organization's work, suggesting relief efforts.\n",
      "Segmented chapters from video file saved to: C:\\Users\\ANT pc\\Downloads\\AskJunior.ai Assessment Project\\Document-Chapter-Segmentation\\results\\video file\\video_segmented_chapters.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess  # Import subprocess for running FFmpeg commands\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import re\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "# Configure the Gemini API\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Function to split video into smaller segments using FFmpeg\n",
    "def split_video_ffmpeg(video_file_path, max_duration):\n",
    "    segment_path_template = \"segment_%03d.mp4\"\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", video_file_path,\n",
    "        \"-c\", \"copy\",\n",
    "        \"-map\", \"0\",\n",
    "        \"-segment_time\", str(max_duration),\n",
    "        \"-f\", \"segment\",\n",
    "        segment_path_template\n",
    "    ]\n",
    "    subprocess.run(command)\n",
    "\n",
    "    # Generate a list of segment file names\n",
    "    segments = [segment_path_template % i for i in range(len(os.listdir('.')))]\n",
    "    return segments\n",
    "\n",
    "# Function to transcribe video with segmented chapters\n",
    "def transcribe_video_with_segmented_chapters(video_file_path):\n",
    "    model = genai.GenerativeModel('models/gemini-1.5-flash-8b')\n",
    "    prompt = \"\"\"Please transcribe this video file and segment the transcription into meaningful chapters. \n",
    "    For each chapter, provide 5-6 detailed bullet points that summarize the key ideas, themes, or events discussed in that chapter. \n",
    "    Do not include any introductory phrases, personal comments, or conversational language. \n",
    "    Provide only the segmented chapters followed by the bullet points in the output.\"\"\"\n",
    "\n",
    "    max_duration = 300  # Example: 5 minutes\n",
    "    split_video_ffmpeg(video_file_path, max_duration)\n",
    "\n",
    "    all_transcriptions = []\n",
    "    chapter_counter = 1  # Initialize chapter counter\n",
    "\n",
    "    # Process each segment\n",
    "    for segment in os.listdir('.'):\n",
    "        if segment.startswith(\"segment_\") and segment.endswith(\".mp4\"):\n",
    "            video_file = genai.upload_file(path=segment, display_name=os.path.basename(segment))\n",
    "            print(f\"Video segment {segment} uploaded successfully.\")\n",
    "\n",
    "            time.sleep(30)\n",
    "\n",
    "            for attempt in range(3):\n",
    "                try:\n",
    "                    response = model.generate_content([prompt, video_file])\n",
    "                    print(\"Transcription response received for segment:\", segment)\n",
    "\n",
    "                    # Update chapter numbering in the response text\n",
    "                    response_text = response.text\n",
    "\n",
    "                    # Find all chapters in the response and update their numbering\n",
    "                    chapters = re.findall(r'Chapter \\d+', response_text)\n",
    "                    for chapter in chapters:\n",
    "                        current_chapter_number = int(chapter.split()[-1])\n",
    "                        new_chapter_number = chapter_counter + current_chapter_number - 1\n",
    "                        response_text = response_text.replace(chapter, f\"Chapter {new_chapter_number}\")\n",
    "\n",
    "                    chapter_counter += len(chapters)  # Increment chapter counter by the number of chapters found\n",
    "\n",
    "                    all_transcriptions.append(response_text)\n",
    "                    break  # Exit the retry loop if successful\n",
    "                except Exception as e:\n",
    "                    print(f\"Attempt {attempt + 1}: Error during transcription for segment {segment}: {e}\")\n",
    "                    time.sleep(5)\n",
    "\n",
    "    return \"\\n\\n\".join(all_transcriptions)\n",
    "\n",
    "# Define the video file path\n",
    "video_file_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'data', 'samples', 'video.mp4'))\n",
    "\n",
    "# Example usage\n",
    "transcription_result = transcribe_video_with_segmented_chapters(video_file_path)\n",
    "if transcription_result:\n",
    "    print(\"Transcription Result:\\n\", transcription_result)\n",
    "else:\n",
    "    print(\"Failed to transcribe video.\")\n",
    "\n",
    "# Define the results folder path\n",
    "results_folder = os.path.abspath(os.path.join(os.getcwd(), '..', 'results', 'video file'))\n",
    "\n",
    "# Create the results directory if it doesn't exist\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "# Define the output file path for the segmented chapters of the video file\n",
    "output_md_file_path = os.path.join(results_folder, 'video_segmented_chapters.md')\n",
    "\n",
    "# Save the segmented chapters to the specified markdown file\n",
    "if transcription_result:\n",
    "    with open(output_md_file_path, 'w') as f:\n",
    "        f.write(transcription_result)\n",
    "    print(f\"Segmented chapters from video file saved to: {output_md_file_path}\")\n",
    "else:\n",
    "    print(\"No transcription result to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473bf5f6-4ea2-4a39-a3d2-97f375d182b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "703f3a07-cbca-4da7-8ec8-d1d5da7a9edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio segment segment_0_300.mp3 uploaded successfully.\n",
      "Transcription response received for segment: segment_0_300.mp3\n",
      "Audio segment segment_300_600.mp3 uploaded successfully.\n",
      "Transcription response received for segment: segment_300_600.mp3\n",
      "Audio segment segment_600_619.mp3 uploaded successfully.\n",
      "Transcription response received for segment: segment_600_619.mp3\n",
      "Transcription Result:\n",
      " Chapter 1: War Crimes Against Medics\n",
      "\n",
      "*   Social conventions and international law aim to limit deliberate targeting on the battlefield.\n",
      "*   Despite these conventions, individuals deemed off-limits are sometimes intentionally targeted during combat.\n",
      "*   Rules and customs of war have existed for centuries.\n",
      "*   In the 18th century, the officer class in armies was largely made up of the aristocracy.\n",
      "*   The desire to conduct war in a \"gentlemanly\" fashion often led to the avoidance of targeting officers.\n",
      "*   The deliberate targeting of officers was considered barbaric.\n",
      "\n",
      "\n",
      "Chapter 2: Targeting Officers During the American Revolution\n",
      "\n",
      "*   Although not official policy, the Continental Army created sharpshooter units during the American Revolution.\n",
      "*   These sharpshooters used highly accurate long-range rifles to pick off specific targets, like officers.\n",
      "*   This contrasted with the regular army's use of less accurate smoothbore muskets.\n",
      "*   Under the command of frontiersman Daniel Morgan, sharpshooters played a decisive role in the Battle of Saratoga (1777).\n",
      "*   Legend attributes the killing of British General Simon Fraser to one of Morgan's sharpshooters, Timothy Murphy.\n",
      "*   The targeting of British officers by Morgan's men disrupted their advance and contributed to the Continental Army's victory.\n",
      "\n",
      "\n",
      "Chapter 3: Formalization of Restrictions on Targeting\n",
      "\n",
      "*   Restrictions on targeting specific individuals were formalized into treaties.\n",
      "*   The prohibition of medics and medical personnel as legitimate targets is a prominent restriction.\n",
      "*   Some nations not only ignored these international guidelines, but also used the deliberate targeting of medics as a standard tactic.\n",
      "*   The Hague and Geneva Conventions govern the conduct of soldiers on the battlefield.\n",
      "*   The Geneva Conventions have been updated multiple times since 1864.\n",
      "*   Deliberate attacks on medics or unnecessary hindrances to their duties are considered war crimes.\n",
      "\n",
      "\n",
      "Chapter 4:  Protection of Medics Under International Law\n",
      "\n",
      "*   Medics are not to be taken as prisoners of war.\n",
      "*   If captured, medics should be returned to friendly lines as soon as practical.\n",
      "*   No distinction is to be made between military medical staff and civilians.\n",
      "*   Temporary auxiliary medical personnel, such as stretcher-bearers, are also considered non-combatants.\n",
      "*   These individuals deserve the same consideration as designated medics.\n",
      "*   Medics are allowed to carry weapons for personal protection or to defend the wounded.\n",
      "\n",
      "\n",
      "Chapter 5: Exceptions and Conditions Under the Conventions\n",
      "\n",
      "*   Medics forfeit their non-combatant status if they engage in offensive combat.\n",
      "*   During World War II, medics largely did not carry weapons, though there were some exceptions.\n",
      "*   Identification of medics and their protective status were important factors.\n",
      "*   The precise wording of treaties has evolved over time.\n",
      "*  Medics were often more than willing to seek out officers for specific targeting, regardless of its barbaric nature.\n",
      "\n",
      "\n",
      "Chapter 6\n",
      "\n",
      "*   International conventions, primarily the Geneva and Hague Conventions, established special status for medical personnel.\n",
      "*   The red cross on a white background was a common visual identifier for medical personnel.\n",
      "*   The symbol was displayed on tents, vehicles, and equipment to quickly identify medical personnel.\n",
      "*   This symbolic representation aimed to protect medical personnel from deliberate attack.\n",
      "*   The conventions were designed to ensure respect for medical personnel during wartime.\n",
      "\n",
      "\n",
      "Chapter 7\n",
      "\n",
      "*   Most major powers during World War II, including the United States, Great Britain, and Germany, signed the Geneva Convention.\n",
      "*   In general, medical personnel were respected and not deliberately targeted on the Western Front.\n",
      "*   Exceptions occurred where enemy forces intentionally targeted medical personnel.\n",
      "*   Violations of the Hague and Geneva Conventions occurred on both sides.\n",
      "*   Despite exceptions, respect for non-combatant status was generally maintained.\n",
      "\n",
      "Chapter 8\n",
      "\n",
      "*   The Soviet Union did not sign the Geneva Convention.\n",
      "*   Nazi treatment of Soviet prisoners and medical personnel was largely without regard to international law.\n",
      "*   Medical personnel on the Eastern Front were frequently treated as enemy combatants.\n",
      "*   Soviet POW camps held poor conditions, often due to deliberate underfeeding by Nazi regime.\n",
      "*   The treatment of Soviet medical personnel served Nazi ideological goals related to \"Lebensraum\" or living space.\n",
      "\n",
      "Chapter 9\n",
      "\n",
      "*   In the Pacific Theater, Japan did sign the Hague Convention in 1907, and the Geneva Convention of 1929.\n",
      "*   However, Japan did not ratify the Geneva Convention, in part due to fear of Allied powers using the treaty.\n",
      "*   Japan's actions often violated the non-combatant status of medical personnel.\n",
      "*   Medical personnel were often targeted in the Pacific Theater.\n",
      "*   Japanese leadership considered the treaty as a way to encourage American attacks on Japanese cities.\n",
      "\n",
      "Chapter 10\n",
      "\n",
      "*   Medical personnel in the Pacific Theater often had to take extra precautions to ensure their safety.\n",
      "*   Many medical personnel in the Pacific Theater removed identifying insignia in an attempt to avoid being targeted.\n",
      "*   Medical personnel frequently carried weapons and fought alongside their comrades, despite the violation of the Geneva Convention.\n",
      "*   American medic Desmond Doss noted the Japanese obsession with targeting medical personnel, especially for their effect on morale.\n",
      "*   The actions of medics were crucial in determining the outcomes of many battles, providing life-saving care to injured soldiers.\n",
      "\n",
      "\n",
      "Chapter 11\n",
      "\n",
      "*   Delayed medical attention for wounded soldiers could have serious consequences.\n",
      "*   The concept of legitimate and illegitimate targets in war has been established for centuries.\n",
      "*   Social conventions and informal treaties have influenced the designation of targets.\n",
      "*   The concept of legitimate and illegitimate targets has been ignored to gain an advantage on the battlefield.\n",
      "*   The historical precedent demonstrates a disregard for established rules of engagement in warfare.\n",
      "\n",
      "Segmented chapters from audio file saved to: C:\\Users\\ANT pc\\Downloads\\AskJunior.ai Assessment Project\\Document-Chapter-Segmentation\\results\\audio file\\audio_segmented_chapters.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pydub import AudioSegment  # Import AudioSegment from pydub\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import re\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "# Configure the Gemini API\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Function to split audio into smaller segments using pydub\n",
    "def split_audio(audio_file_path, max_duration):\n",
    "    audio = AudioSegment.from_file(audio_file_path)\n",
    "    duration = len(audio)  # Duration in milliseconds\n",
    "    segments = []\n",
    "\n",
    "    for start in range(0, duration, max_duration * 1000):  # Convert max_duration to milliseconds\n",
    "        end = min(start + max_duration * 1000, duration)\n",
    "        segment = audio[start:end]\n",
    "        segment_path = f\"segment_{start // 1000}_{end // 1000}.mp3\"  # Naming segments in seconds\n",
    "        segment.export(segment_path, format=\"mp3\")\n",
    "        segments.append(segment_path)\n",
    "\n",
    "    return segments\n",
    "\n",
    "# Function to transcribe audio with segmented chapters\n",
    "def transcribe_audio_with_segmented_chapters(audio_file_path):\n",
    "    model = genai.GenerativeModel('models/gemini-1.5-flash-8b')\n",
    "    prompt = \"\"\"Please transcribe this audio file and segment the transcription into meaningful chapters. \n",
    "    For each chapter, provide 5-6 detailed bullet points that summarize the key ideas, themes, or events discussed in that chapter. \n",
    "    Do not include any introductory phrases, personal comments, or conversational language. \n",
    "    Provide only the segmented chapters followed by the bullet points in the output.\"\"\"\n",
    "\n",
    "    max_duration = 300  # Example: 5 minutes\n",
    "    audio_segments = split_audio(audio_file_path, max_duration)\n",
    "\n",
    "    all_transcriptions = []\n",
    "    chapter_counter = 1  # Initialize chapter counter\n",
    "\n",
    "    # Process each segment\n",
    "    for segment in audio_segments:\n",
    "        audio_file = genai.upload_file(path=segment, display_name=os.path.basename(segment))\n",
    "        print(f\"Audio segment {segment} uploaded successfully.\")\n",
    "\n",
    "        time.sleep(30)\n",
    "\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                response = model.generate_content([prompt, audio_file])\n",
    "                print(\"Transcription response received for segment:\", segment)\n",
    "\n",
    "                # Update chapter numbering in the response text\n",
    "                response_text = response.text\n",
    "\n",
    "                # Find all chapters in the response and update their numbering\n",
    "                chapters = re.findall(r'Chapter \\d+', response_text)\n",
    "                for chapter in chapters:\n",
    "                    current_chapter_number = int(chapter.split()[-1])\n",
    "                    new_chapter_number = chapter_counter + current_chapter_number - 1\n",
    "                    response_text = response_text.replace(chapter, f\"Chapter {new_chapter_number}\")\n",
    "\n",
    "                chapter_counter += len(chapters)  # Increment chapter counter by the number of chapters found\n",
    "\n",
    "                all_transcriptions.append(response_text)\n",
    "                break  # Exit the retry loop if successful\n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {attempt + 1}: Error during transcription for segment {segment}: {e}\")\n",
    "                time.sleep(5)\n",
    "\n",
    "    return \"\\n\\n\".join(all_transcriptions)\n",
    "\n",
    "# Define the audio file path\n",
    "audio_file_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'data', 'samples', 'audio.mp3'))\n",
    "\n",
    "# Example usage\n",
    "transcription_result = transcribe_audio_with_segmented_chapters(audio_file_path)\n",
    "if transcription_result:\n",
    "    print(\"Transcription Result:\\n\", transcription_result)\n",
    "else:\n",
    "    print(\"Failed to transcribe audio.\")\n",
    "\n",
    "# Define the results folder path\n",
    "results_folder = os.path.abspath(os.path.join(os.getcwd(), '..', 'results', 'audio file'))\n",
    "\n",
    "# Create the results directory if it doesn't exist\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "# Define the output file path for the segmented chapters of the audio file\n",
    "output_md_file_path = os.path.join(results_folder, 'audio_segmented_chapters.md')\n",
    "\n",
    "# Save the segmented chapters to the specified markdown file\n",
    "if transcription_result:\n",
    "    with open(output_md_file_path, 'w') as f:\n",
    "        f.write(transcription_result)\n",
    "    print(f\"Segmented chapters from audio file saved to: {output_md_file_path}\")\n",
    "else:\n",
    "    print(\"No transcription result to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6165bb6-4ced-4df0-a8d7-6899eaf42142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c424e779-9d9b-4567-9d67-0c450164de08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49777142-99f2-477a-97d8-17b77fc3e574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting yt-dlp\n",
      "  Downloading yt_dlp-2025.1.15-py3-none-any.whl.metadata (172 kB)\n",
      "Downloading yt_dlp-2025.1.15-py3-none-any.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.2/3.2 MB 20.8 MB/s eta 0:00:00\n",
      "Installing collected packages: yt-dlp\n",
      "Successfully installed yt-dlp-2025.1.15\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a46963ad-3bcf-40df-bdd2-fb63eb856445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai-whisper in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (20240930)\n",
      "Requirement already satisfied: numba in c:\\anaconda3\\lib\\site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from openai-whisper) (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from openai-whisper) (2.5.1+cu118)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda3\\lib\\site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: more-itertools in c:\\anaconda3\\lib\\site-packages (from openai-whisper) (10.3.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from openai-whisper) (0.8.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\anaconda3\\lib\\site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ant pc\\appdata\\roaming\\python\\python312\\site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda3\\lib\\site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai-whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acce2ac5-70c9-4ade-ad13-f1318d69e110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting uuid\n",
      "  Downloading uuid-1.30.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: uuid\n",
      "  Building wheel for uuid (setup.py): started\n",
      "  Building wheel for uuid (setup.py): finished with status 'done'\n",
      "  Created wheel for uuid: filename=uuid-1.30-py3-none-any.whl size=6508 sha256=41ede8471bf83ae62288d27ee8ad312ddb1570fe7756fd9781c845e73d64e9ba\n",
      "  Stored in directory: c:\\users\\ant pc\\appdata\\local\\pip\\cache\\wheels\\35\\34\\36\\b9f3546da107cf37bab75cdb3ce1ebd8d744648985d0111ca1\n",
      "Successfully built uuid\n",
      "Installing collected packages: uuid\n",
      "Successfully installed uuid-1.30\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93f857-31fd-4c1b-ba42-8679410aef85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a4be2-959e-4495-afe0-28b992db0bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b7eb7b5-d5ab-4416-a31c-c1c04fb0168c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the URL of the video (YouTube, Khan Academy, TED Talks, etc.):  https://www.youtube.com/watch?v=UkkEZ1F0WwU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading video...\n",
      "Downloaded video from: https://www.youtube.com/watch?v=UkkEZ1F0WwU\n",
      "Converting video to audio...\n",
      "Audio saved to: downloaded_videos\\audio_6fc0ca77.mp3\n",
      "Splitting audio into segments...\n",
      "Transcribing downloaded_videos\\audio_6fc0ca77.mp3_0.mp3...\n",
      "Loading Whisper model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANT pc\\AppData\\Roaming\\Python\\Python312\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_6fc0ca77.mp3_1.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_6fc0ca77.mp3_2.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_6fc0ca77.mp3_3.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_6fc0ca77.mp3_4.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_6fc0ca77.mp3_5.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_6fc0ca77.mp3_6.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_6fc0ca77.mp3_7.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_6fc0ca77.mp3_8.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "\n",
      "Generating chaptered summary...\n",
      "\n",
      "Chaptered Content:\n",
      "\n",
      "Chapter 1\n",
      " The speaker is reviewing the Vande Bharat train.\n",
      " The review focuses on specific features and design aspects.\n",
      " The speaker highlights features not covered in previous reviews.\n",
      " The speaker points out a lack of detailed information during a rushed presentation.\n",
      " The speaker promises a perspective on the train's structure and design.\n",
      "\n",
      "\n",
      "Chapter 2\n",
      " The exterior of the train, including the engine and windows, is described.\n",
      " The controls and functionalities, like switches and buttons, are discussed.\n",
      " The speaker notes the train's modern design compared to traditional models.\n",
      " The train's safety features, such as safety measures and controls, are highlighted.\n",
      "\n",
      "\n",
      "Chapter 3\n",
      " The speaker highlights the advancements in train technology.\n",
      " The speaker discusses the train's new features compared to previous models.\n",
      " Improvements in safety, technology and overall design are noted.\n",
      " The speaker highlights specific design features.\n",
      " The chapter emphasizes the train's innovative features.\n",
      "\n",
      "\n",
      "Chapter 4\n",
      " The speaker describes the process of testing and trials.\n",
      " Removal of cattle carriages is noted during the trials.\n",
      " The current trials and the train's eventual form are discussed.\n",
      " The speaker shares observations about the train's performance during trials.\n",
      " Issues related to trials and modifications are brought up.\n",
      "\n",
      "\n",
      "Chapter 5\n",
      " The speaker describes the overall performance of the train.\n",
      " Comparisons are made with other similar models.\n",
      " The speaker expresses positive sentiments about the train's performance.\n",
      " The train's improvements and advancements are highlighted.\n",
      " The chapter emphasizes the significance of the train's launch.\n",
      "\n",
      "\n",
      "Chapter 6\n",
      " The speaker notes the train's potential impact on the rail network.\n",
      " The train's significance in Indian Railways is emphasized.\n",
      " The speaker's limited experience is acknowledged.\n",
      " The importance of the train to the country is implied.\n",
      " The potential benefits and further developments of the train are discussed.\n",
      "\n",
      "\n",
      "Chapter 7\n",
      " The chapter focuses on the ongoing trials and improvements in the train's design.\n",
      " Specific changes made to the train are mentioned.\n",
      " Various versions and design aspects of the train are discussed.\n",
      " The train's journey to completion and its current status is addressed.\n",
      " The speaker's final thoughts about the train's features are provided.\n",
      "\n",
      "\n",
      "Chapter 8\n",
      " The speaker concludes with a summary of the train's features and design.\n",
      " The speaker's perspective and overall appraisal of the train are shared.\n",
      " The emphasis is on the overall significance of the train's design and innovations.\n",
      " A summary of the new and improved features is highlighted.\n",
      " A final perspective about the train and its development is provided.\n",
      "\n",
      "\n",
      "\n",
      "Segmented chapters from youtube video url saved to: C:\\Users\\ANT pc\\Downloads\\AskJunior.ai Assessment Project\\Document-Chapter-Segmentation\\results\\youtube transcription\\youtube_segmented_chapters.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import whisper\n",
    "import yt_dlp\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Gemini API\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "def download_video(video_url, output_dir):\n",
    "    \"\"\"Download video using yt-dlp with safe filename handling\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Generate safe filename with UUID\n",
    "    unique_id = str(uuid.uuid4())[:8]\n",
    "    output_path = os.path.join(output_dir, f\"video_{unique_id}.mp4\")\n",
    "    \n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',  # Prefer audio-only formats\n",
    "        'outtmpl': output_path,\n",
    "        'quiet': True,\n",
    "        'no_warnings': True\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([video_url])\n",
    "        print(f\"Downloaded video from: {video_url}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading video: {e}\")\n",
    "        raise\n",
    "\n",
    "def convert_video_to_audio(video_path, audio_path):\n",
    "    \"\"\"Convert video to audio using ffmpeg\"\"\"\n",
    "    try:\n",
    "        print(\"Converting video to audio...\")\n",
    "        subprocess.run(['ffmpeg', '-i', video_path, '-vn', '-acodec', 'mp3', audio_path], check=True)\n",
    "        print(f\"Audio saved to: {audio_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during audio conversion: {e}\")\n",
    "        raise\n",
    "\n",
    "def split_audio(audio_path, segment_length_ms=60000):\n",
    "    \"\"\"Split the audio into parts\"\"\"\n",
    "    audio = AudioSegment.from_mp3(audio_path)\n",
    "    segments = []\n",
    "    for i in range(0, len(audio), segment_length_ms):\n",
    "        segment = audio[i:i+segment_length_ms]\n",
    "        segment_path = f\"{audio_path}_{i // segment_length_ms}.mp3\"\n",
    "        segment.export(segment_path, format=\"mp3\")\n",
    "        segments.append(segment_path)\n",
    "    return segments\n",
    "\n",
    "def transcribe_with_whisper(audio_path, language=\"hi\"):\n",
    "    \"\"\"Transcribe audio using Whisper model\"\"\"\n",
    "    print(\"Loading Whisper model...\")\n",
    "    model = whisper.load_model(\"base\")  # You can use \"small\" or \"medium\" for better accuracy\n",
    "    \n",
    "    print(\"Transcribing audio...\")\n",
    "    result = model.transcribe(\n",
    "        audio_path,\n",
    "        language=language,  # Specify Hindi language\n",
    "        task=\"transcribe\",  # For transcription (use \"translate\" for direct English translation)\n",
    "    )\n",
    "    \n",
    "    return result[\"text\"]\n",
    "\n",
    "def segment_transcription(transcription):\n",
    "    \"\"\"Use Gemini to segment transcription into meaningful chapters\"\"\"\n",
    "    model = genai.GenerativeModel('models/gemini-1.5-flash-8b')\n",
    "    \n",
    "    prompt = f\"\"\"Given this transcription, segment it into meaningful chapters. For each chapter, provide 5-6 detailed bullet points that summarize the key points, themes, or events discussed.\n",
    "\n",
    "Transcription:\n",
    "{transcription}\n",
    "\n",
    "Please format the output as follows for each chapter:\n",
    "\n",
    "Chapter X\n",
    " [First key point]\n",
    " [Second key point]\n",
    " [Third key point]\n",
    " [Fourth key point]\n",
    " [Fifth key point]\n",
    "\n",
    "Focus on main ideas and maintain a clear narrative flow between chapters. Do not include any introductory phrases or personal comments\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during chapter segmentation: {e}\")\n",
    "        raise\n",
    "\n",
    "def cleanup_files(file_paths):\n",
    "    \"\"\"Clean up temporary files\"\"\"\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            if os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning up file {file_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        video_url = input(\"Enter the URL of the video (YouTube, Khan Academy, TED Talks, etc.): \")\n",
    "        output_directory = \"downloaded_videos\"\n",
    "        \n",
    "        # Download video\n",
    "        print(\"Downloading video...\")\n",
    "        video_path = download_video(video_url, output_directory)\n",
    "\n",
    "        # Convert video to audio\n",
    "        audio_path = os.path.join(output_directory, f\"audio_{str(uuid.uuid4())[:8]}.mp3\")\n",
    "        convert_video_to_audio(video_path, audio_path)\n",
    "\n",
    "        # Split audio into segments\n",
    "        print(\"Splitting audio into segments...\")\n",
    "        audio_segments = split_audio(audio_path)\n",
    "\n",
    "        # Transcribe each audio segment with Whisper\n",
    "        transcriptions = []\n",
    "        for segment in audio_segments:\n",
    "            print(f\"Transcribing {segment}...\")\n",
    "            transcription = transcribe_with_whisper(segment)\n",
    "            transcriptions.append(transcription)\n",
    "\n",
    "        # Combine transcriptions into a single string\n",
    "        full_transcription = \" \".join(transcriptions)\n",
    "\n",
    "        # Segment using Gemini\n",
    "        print(\"\\nGenerating chaptered summary...\")\n",
    "        chaptered_content = segment_transcription(full_transcription)\n",
    "        print(\"\\nChaptered Content:\\n\")\n",
    "        print(chaptered_content)\n",
    "        \n",
    "        # Define the results folder path\n",
    "        results_folder = os.path.abspath(os.path.join(os.getcwd(), '..', 'results', 'youtube transcription'))\n",
    "        \n",
    "        # Create the results directory if it doesn't exist\n",
    "        os.makedirs(results_folder, exist_ok=True)\n",
    "        \n",
    "        # Define the output file path for the segmented chapters of the audio file\n",
    "        output_md_file_path = os.path.join(results_folder, 'youtube_segmented_chapters.md')\n",
    "        \n",
    "        if chaptered_content:\n",
    "            with open(output_md_file_path, 'w') as f:\n",
    "                f.write(chaptered_content)\n",
    "            print(f\"Segmented chapters from youtube video url saved to: {output_md_file_path}\")\n",
    "        else:\n",
    "            print(\"No transcription result to save.\")\n",
    "        \n",
    "        # Cleanup\n",
    "        cleanup_files([video_path, audio_path] + audio_segments)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b04c0-e90a-45eb-965a-c2e4af7ef644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb6b521b-3cec-492b-b748-ca2597ebda05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\ANT\n",
      "[nltk_data]     pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the URL of the video (YouTube, Khan Academy, TED Talks, etc.):  https://www.youtube.com/watch?v=YShmfsVCcZ4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading video...\n",
      "Downloaded video from: https://www.youtube.com/watch?v=YShmfsVCcZ4\n",
      "Converting video to audio...\n",
      "Audio saved to: downloaded_videos\\audio_3e47ee8f.mp3\n",
      "Splitting audio into segments...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_0.mp3...\n",
      "Loading Whisper model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANT pc\\AppData\\Roaming\\Python\\Python312\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_1.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_2.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_3.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_4.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_5.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_6.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_7.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_8.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_9.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_10.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_11.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_12.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_13.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_14.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_15.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_16.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_17.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_18.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "Transcribing downloaded_videos\\audio_3e47ee8f.mp3_19.mp3...\n",
      "Loading Whisper model...\n",
      "Transcribing audio...\n",
      "\n",
      "Generating chaptered summary...\n",
      "\n",
      "Chaptered Content:\n",
      "\n",
      "Chapter 1: The Boeing B-17 Flying Fortress\n",
      "\n",
      " The B-17's development began in the 1930s in response to potential threats to the US from distant locations like Hawaii, Alaska, and Panama.\n",
      " The first prototype was created by Boeing in 1935.\n",
      " Limited production ran in 1937. By 1941, a small fleet of B-17s existed when the US entered the war.\n",
      " The name \"Flying Fortress\" originated from a reporter's description of the prototype due to its numerous machine guns.\n",
      " Multiple variants of the B-17 were produced throughout the war, with increasing defensive capabilities and performance enhancements.\n",
      " The B-17G is considered the definitive variant, with over 8600 produced.\n",
      "\n",
      "\n",
      "Chapter 2: B-17 Dimensions, Performance, and Armament\n",
      "\n",
      " The B-17G had dimensions of 74 feet 9 inches in length, nearly 104 feet wingspan, and a height of 19 feet 1 inch.\n",
      " The B-17G weighed approximately 36,000 pounds empty, and up to 65,000 pounds with a full bomb load and equipment.\n",
      " The B-17G was made primarily of aluminum, which contributed to its lighter weight compared to steel.\n",
      " Four Wright Cyclone R-1820 engines, each producing 1200 horsepower, propelled the aircraft.\n",
      "  Cruising speed was typically between 170-200 mph, with a maximum speed of 300 mph and a service ceiling of 35,000 feet.\n",
      " The aircraft's 2800-gallon fuel tank provided a range of approximately 2000 miles, varying based on load, weather, etc.\n",
      "\n",
      "\n",
      "Chapter 3: B-17 Bomb Load and Defense\n",
      "\n",
      " The B-17G typically carried a bomb load of 6000 pounds, expandable to 8,000 pounds or more with external racks.\n",
      " A comprehensive defensive system featured 12 .50-caliber machine guns strategically positioned around the fuselage, nose, chin turret, dorsal turret, waist gunners, tail gunner, and ball turret.\n",
      " Ammunition supply for each gun was limited to a minute's worth of rounds due to space and weight constraints.\n",
      " The limitations of the machine gun ammunition and the positions of the guns necessitated careful aim and situational awareness by the crew.\n",
      "\n",
      "Chapter 4: B-17 Crew, Communication, and the Norden Bombsight\n",
      "\n",
      " The B-17 was crewed by 10 men, each with a specific role (pilot, co-pilot, bombardier, navigator, engineer, radio operator, waist gunners, tail gunner, ball turret gunner).\n",
      " Unpressurized cabins required external oxygen for crew, necessitating wool-lined clothing and internal heating.\n",
      " Crew communication relied on an intercom system.\n",
      " The Norden bombsight was a crucial component for accurate bombing from high altitudes.\n",
      " The Norden bombsight allowed the bombardier to input aircraft data, align on a target, and release the bomb payload at the precise moment.\n",
      " Despite the Norden bombsight, hitting targets proved challenging due to combat conditions.\n",
      "\n",
      "Chapter 5: B-17 Combat Experience and Legacy\n",
      "\n",
      " The B-17 served in numerous theaters and was highly regarded for reliability and performance.\n",
      " Bombing missions over Europe were particularly perilous due to Luftwaffe fighter resistance.\n",
      " B-17s flew in formations to provide mutual support with their machine guns, though vulnerable to enemy attacks.\n",
      "  The B-17's ability to endure significant damage, despite numerous losses was a key factor.\n",
      "  A significant loss rate for B-17 crews and aircraft, about 37%, was suffered throughout the war.\n",
      " The life expectancy of a B-17 and its crew was about 11 missions during the war's peak.\n",
      "\n",
      "\n",
      "Chapter 6: The Avro Lancaster Bomber\n",
      "\n",
      " The Avro Lancaster was a British heavy bomber primarily used for night-time bombing missions during World War II.\n",
      "  It spearheaded the Allied Strategic Bombing Campaign against Nazi Germany.\n",
      "  It was designed by Roy Chadwick and the Avro team, deploying its first prototype in 1941.\n",
      " The Lancaster was used operationally in 1942.\n",
      "  Over 7,377 Lancasters were built, with a 920 company production network involved.\n",
      "  Only 3,445 Lancasters survived the war, typically averaging 21 missions.\n",
      "\n",
      "\n",
      "Chapter 7: Lancaster Dimensions, Performance, and Armament\n",
      "\n",
      " The Lancaster had dimensions of 69 feet 6 inches in length, 102 feet wingspan, and 20 feet 6 inches height.\n",
      " The Lancaster weighed over 36,000 pounds empty, and was capable of carrying significantly more payload (up to 33,100 pounds).\n",
      " Four Rolls-Royce Merlin XX V12 liquid-cooled piston engines powered the Lancaster.\n",
      " The engines produced 1,280 horsepower and 954 kilowatts.\n",
      " Typical cruising speed was 200 mph, reaching 275 mph at 15,000 feet.\n",
      " Fuel tanks and bomb load could achieve a range of 2,530 miles.\n",
      "\n",
      "\n",
      "Chapter 8: Lancaster Bombing Capabilities and Bombsights\n",
      "\n",
      " The Lancaster was uniquely equipped to carry heavier bomb loads, including the 12,000-pound bunker busters.\n",
      " The Lancaster bomb bay was adaptable to the 'Bouncing Bomb'.\n",
      " Early Lancaster bombsights were of a rudimentary design (Mark IX), which were replaced by the Mark XIV (vector-based) in 1943.\n",
      " The improved bombsight allowed for more complex calculations and adjustments during flight.\n",
      "\n",
      "Chapter 9: Lancaster Crew, Armament, and Bomb Load\n",
      "\n",
      " The Lancaster crew consisted of seven men, with specific roles (pilot, engineer, navigator, wireless operator, bomb aimer, rear gunner, mid-upper gunner).\n",
      " Armament included 8 .303-inch Browning machine guns across three hydraulically powered turrets (nose, dorsal, and tail).\n",
      " Bomb loads of 14,000 pounds were possible. The Lancaster carried numerous bomb sizes (1,000-4,000 pounds).\n",
      " Bomb doors were later modified for heavier payloads.\n",
      "\n",
      "Chapter 10: Lancaster Communications and Combat\n",
      "\n",
      " Communication between Lancaster crews, other aircraft, and bases was crucial.\n",
      " The wireless operator identified friend or foe and provided signals to confuse the enemy during combat.\n",
      " The pilot utilized corkscrew turns to avoid enemy fire.\n",
      " The rear gunner was instrumental in early detection of enemy aircraft.\n",
      "\n",
      "\n",
      "Chapter 11: Lancaster Post-War Use and Legacy\n",
      "\n",
      "  The Lancaster was modified and refitted after the war for aerial surveys, long-distance flights, and other duties.\n",
      " Fifteen variants of the Lancaster were developed.\n",
      "  Only 17 Lancasters remain (with 2 airworthy).\n",
      "  Post-war use by the RAF, RAAF, and other forces continued.\n",
      "  The Lancaster was eventually superseded by the Avro Lincoln in 1954.\n",
      "  Overhauled Lancasters were used by French naval aviation through the 1960s.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating segmentation quality...\n",
      "Average Semantic Consistency: 0.2460\n",
      "Chapter 1 Semantic Consistency: 0.0947\n",
      "Chapter 2 Semantic Consistency: 0.7933\n",
      "Chapter 3 Semantic Consistency: 0.0947\n",
      "Chapter 4 Semantic Consistency: 0.4404\n",
      "Chapter 5 Semantic Consistency: 0.0947\n",
      "Chapter 6 Semantic Consistency: 0.3783\n",
      "Chapter 7 Semantic Consistency: 0.0947\n",
      "Chapter 8 Semantic Consistency: 0.3651\n",
      "Chapter 9 Semantic Consistency: 0.0947\n",
      "Chapter 10 Semantic Consistency: 0.5571\n",
      "Chapter 11 Semantic Consistency: 0.0947\n",
      "Chapter 12 Semantic Consistency: 0.4382\n",
      "Chapter 13 Semantic Consistency: 0.0947\n",
      "Chapter 14 Semantic Consistency: 0.2112\n",
      "Chapter 15 Semantic Consistency: 0.0947\n",
      "Chapter 16 Semantic Consistency: 0.4256\n",
      "Chapter 17 Semantic Consistency: 0.0947\n",
      "Chapter 18 Semantic Consistency: 0.3227\n",
      "Chapter 19 Semantic Consistency: 0.0947\n",
      "Chapter 20 Semantic Consistency: 0.3808\n",
      "Chapter 21 Semantic Consistency: 0.0947\n",
      "Chapter 22 Semantic Consistency: 0.3604\n",
      "Chapter 23 Semantic Consistency: 0.0947\n",
      "Chapter 24 Semantic Consistency: 0.0947\n",
      "Average Relevance Score: 0.5417\n",
      "Chapter 1 Relevance Score: 0\n",
      "Chapter 2 Relevance Score: 3\n",
      "Chapter 3 Relevance Score: 0\n",
      "Chapter 4 Relevance Score: 0\n",
      "Chapter 5 Relevance Score: 0\n",
      "Chapter 6 Relevance Score: 0\n",
      "Chapter 7 Relevance Score: 0\n",
      "Chapter 8 Relevance Score: 0\n",
      "Chapter 9 Relevance Score: 0\n",
      "Chapter 10 Relevance Score: 0\n",
      "Chapter 11 Relevance Score: 0\n",
      "Chapter 12 Relevance Score: 2\n",
      "Chapter 13 Relevance Score: 0\n",
      "Chapter 14 Relevance Score: 2\n",
      "Chapter 15 Relevance Score: 0\n",
      "Chapter 16 Relevance Score: 2\n",
      "Chapter 17 Relevance Score: 0\n",
      "Chapter 18 Relevance Score: 1\n",
      "Chapter 19 Relevance Score: 0\n",
      "Chapter 20 Relevance Score: 0\n",
      "Chapter 21 Relevance Score: 0\n",
      "Chapter 22 Relevance Score: 3\n",
      "Chapter 23 Relevance Score: 0\n",
      "Chapter 24 Relevance Score: 0\n",
      "Segmented chapters from youtube video url saved to: C:\\Users\\ANT pc\\Downloads\\AskJunior.ai Assessment Project\\Document-Chapter-Segmentation\\results\\youtube transcription\\youtube_segmented_chapters.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import whisper\n",
    "import yt_dlp\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# Ensure nltk resources are downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Gemini API\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "def download_video(video_url, output_dir):\n",
    "    \"\"\"Download video using yt-dlp with safe filename handling\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Generate safe filename with UUID\n",
    "    unique_id = str(uuid.uuid4())[:8]\n",
    "    output_path = os.path.join(output_dir, f\"video_{unique_id}.mp4\")\n",
    "    \n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',  # Prefer audio-only formats\n",
    "        'outtmpl': output_path,\n",
    "        'quiet': True,\n",
    "        'no_warnings': True\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([video_url])\n",
    "        print(f\"Downloaded video from: {video_url}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading video: {e}\")\n",
    "        raise\n",
    "\n",
    "def convert_video_to_audio(video_path, audio_path):\n",
    "    \"\"\"Convert video to audio using ffmpeg\"\"\"\n",
    "    try:\n",
    "        print(\"Converting video to audio...\")\n",
    "        subprocess.run(['ffmpeg', '-i', video_path, '-vn', '-acodec', 'mp3', audio_path], check=True)\n",
    "        print(f\"Audio saved to: {audio_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during audio conversion: {e}\")\n",
    "        raise\n",
    "\n",
    "def split_audio(audio_path, segment_length_ms=60000):\n",
    "    \"\"\"Split the audio into parts\"\"\"\n",
    "    audio = AudioSegment.from_mp3(audio_path)\n",
    "    segments = []\n",
    "    for i in range(0, len(audio), segment_length_ms):\n",
    "        segment = audio[i:i+segment_length_ms]\n",
    "        segment_path = f\"{audio_path}_{i // segment_length_ms}.mp3\"\n",
    "        segment.export(segment_path, format=\"mp3\")\n",
    "        segments.append(segment_path)\n",
    "    return segments\n",
    "\n",
    "def transcribe_with_whisper(audio_path, language=\"hi\"):\n",
    "    \"\"\"Transcribe audio using Whisper model\"\"\"\n",
    "    print(\"Loading Whisper model...\")\n",
    "    model = whisper.load_model(\"base\")  # You can use \"small\" or \"medium\" for better accuracy\n",
    "    \n",
    "    print(\"Transcribing audio...\")\n",
    "    result = model.transcribe(\n",
    "        audio_path,\n",
    "        language=language,  # Specify Hindi language\n",
    "        task=\"transcribe\",  # For transcription (use \"translate\" for direct English translation)\n",
    "    )\n",
    "    \n",
    "    return result[\"text\"]\n",
    "\n",
    "def segment_transcription(transcription):\n",
    "    \"\"\"Use Gemini to segment transcription into meaningful chapters\"\"\"\n",
    "    model = genai.GenerativeModel('models/gemini-1.5-flash-8b')\n",
    "    \n",
    "    prompt = f\"\"\"Given this transcription, segment it into meaningful chapters. For each chapter, provide 5-6 detailed bullet points that summarize the key points, themes, or events discussed.\n",
    "\n",
    "Transcription:\n",
    "{transcription}\n",
    "\n",
    "Please format the output as follows for each chapter:\n",
    "\n",
    "Chapter X\n",
    " [First key point]\n",
    " [Second key point]\n",
    " [Third key point]\n",
    " [Fourth key point]\n",
    " [Fifth key point]\n",
    "\n",
    "Focus on main ideas and maintain a clear narrative flow between chapters. Do not include any introductory phrases or personal comments\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during chapter segmentation: {e}\")\n",
    "        raise\n",
    "\n",
    "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def compute_semantic_consistency(full_transcription, chaptered_content):\n",
    "    \"\"\"Calculate semantic consistency using cosine similarity between full transcription and chapter summaries\"\"\"\n",
    "    full_transcription_embedding = embedding_model.encode([full_transcription])\n",
    "    \n",
    "    # Split chaptered content into individual chapters\n",
    "    chapters = chaptered_content.split(\"\\n\\n\")\n",
    "    \n",
    "    chapter_scores = []\n",
    "    \n",
    "    for chapter in chapters:\n",
    "        # Extract chapter summary (skip chapter title, get bullet points)\n",
    "        lines = chapter.strip().split(\"\\n\")\n",
    "        chapter_summary = \" \".join(lines[1:])  # Skip \"Chapter X\" title\n",
    "        chapter_embedding = embedding_model.encode([chapter_summary])\n",
    "        \n",
    "        # Compute cosine similarity between the full transcription and chapter summary\n",
    "        similarity_score = cosine_similarity(full_transcription_embedding, chapter_embedding)[0][0]\n",
    "        chapter_scores.append(similarity_score)\n",
    "    \n",
    "    avg_semantic_consistency = np.mean(chapter_scores)\n",
    "    return avg_semantic_consistency, chapter_scores\n",
    "\n",
    "def compute_relevance(chaptered_content, relevant_keywords):\n",
    "    \"\"\"Calculate relevance of each chapter based on keyword matching\"\"\"\n",
    "    chapters = chaptered_content.split(\"\\n\\n\")\n",
    "    \n",
    "    relevance_scores = []\n",
    "    \n",
    "    for chapter in chapters:\n",
    "        # Extract chapter summary (skip chapter title, get bullet points)\n",
    "        lines = chapter.strip().split(\"\\n\")\n",
    "        chapter_summary = \" \".join(lines[1:])\n",
    "        \n",
    "        # Tokenize the chapter summary and relevant keywords\n",
    "        chapter_tokens = word_tokenize(chapter_summary.lower())\n",
    "        relevant_tokens = [word.lower() for word in relevant_keywords]\n",
    "        \n",
    "        # Count keyword occurrences in chapter\n",
    "        chapter_token_counts = Counter(chapter_tokens)\n",
    "        relevance_score = sum(chapter_token_counts.get(keyword, 0) for keyword in relevant_tokens)\n",
    "        \n",
    "        relevance_scores.append(relevance_score)\n",
    "    \n",
    "    avg_relevance_score = np.mean(relevance_scores)\n",
    "    return avg_relevance_score, relevance_scores\n",
    "\n",
    "def evaluate_segmentation(full_transcription, chaptered_content, relevant_keywords):\n",
    "    \"\"\"Evaluate segmentation using semantic consistency and relevance metrics\"\"\"\n",
    "    print(\"Evaluating segmentation quality...\")\n",
    "\n",
    "    # Compute semantic consistency\n",
    "    avg_semantic_consistency, chapterwise_semantic_scores = compute_semantic_consistency(full_transcription, chaptered_content)\n",
    "    print(f\"Average Semantic Consistency: {avg_semantic_consistency:.4f}\")\n",
    "    for i, score in enumerate(chapterwise_semantic_scores):\n",
    "        print(f\"Chapter {i+1} Semantic Consistency: {score:.4f}\")\n",
    "    \n",
    "    # Compute relevance\n",
    "    avg_relevance_score, chapterwise_relevance_scores = compute_relevance(chaptered_content, relevant_keywords)\n",
    "    print(f\"Average Relevance Score: {avg_relevance_score:.4f}\")\n",
    "    for i, score in enumerate(chapterwise_relevance_scores):\n",
    "        print(f\"Chapter {i+1} Relevance Score: {score}\")\n",
    "\n",
    "    return avg_semantic_consistency, avg_relevance_score\n",
    "\n",
    "\n",
    "def cleanup_files(file_paths):\n",
    "    \"\"\"Clean up temporary files\"\"\"\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            if os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning up file {file_path}: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        video_url = input(\"Enter the URL of the video (YouTube, Khan Academy, TED Talks, etc.): \")\n",
    "        output_directory = \"downloaded_videos\"\n",
    "        \n",
    "        # Download video\n",
    "        print(\"Downloading video...\")\n",
    "        video_path = download_video(video_url, output_directory)\n",
    "\n",
    "        # Convert video to audio\n",
    "        audio_path = os.path.join(output_directory, f\"audio_{str(uuid.uuid4())[:8]}.mp3\")\n",
    "        convert_video_to_audio(video_path, audio_path)\n",
    "\n",
    "        # Split audio into segments\n",
    "        print(\"Splitting audio into segments...\")\n",
    "        audio_segments = split_audio(audio_path)\n",
    "\n",
    "        # Transcribe each audio segment with Whisper\n",
    "        transcriptions = []\n",
    "        for segment in audio_segments:\n",
    "            print(f\"Transcribing {segment}...\")\n",
    "            transcription = transcribe_with_whisper(segment)\n",
    "            transcriptions.append(transcription)\n",
    "\n",
    "        # Combine transcriptions into a single string\n",
    "        full_transcription = \" \".join(transcriptions)\n",
    "\n",
    "        # Segment using Gemini\n",
    "        print(\"\\nGenerating chaptered summary...\")\n",
    "        chaptered_content = segment_transcription(full_transcription)\n",
    "        print(\"\\nChaptered Content:\\n\")\n",
    "        print(chaptered_content)\n",
    "\n",
    "        # Define relevant keywords (you can adjust based on the content or use a more sophisticated method)\n",
    "        relevant_keywords = [\"bomber\", \"America\", \"Hawaii\", \"training\", \"Boeing\", \"Fortress\", \"Lancaster\", \"Avro\", \"Flying\"]\n",
    "\n",
    "        # Evaluate segmentation quality\n",
    "        evaluate_segmentation(full_transcription, chaptered_content, relevant_keywords)\n",
    "        \n",
    "        # Define the results folder path\n",
    "        results_folder = os.path.abspath(os.path.join(os.getcwd(), '..', 'results', 'youtube transcription'))\n",
    "        \n",
    "        # Create the results directory if it doesn't exist\n",
    "        os.makedirs(results_folder, exist_ok=True)\n",
    "        \n",
    "        # Define the output file path for the segmented chapters of the audio file\n",
    "        output_md_file_path = os.path.join(results_folder, 'youtube_segmented_chapters.md')\n",
    "        \n",
    "        if chaptered_content:\n",
    "            with open(output_md_file_path, 'w') as f:\n",
    "                f.write(chaptered_content)\n",
    "            print(f\"Segmented chapters from youtube video url saved to: {output_md_file_path}\")\n",
    "        else:\n",
    "            print(\"No transcription result to save.\")\n",
    "        \n",
    "        # Cleanup\n",
    "        cleanup_files([video_path, audio_path] + audio_segments)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f77365-4c31-4ae4-b6cb-8141aea0b915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
